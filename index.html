<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>About Me | Zihao Wang&#39;s Portfolio</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Zihao Wang’s Project PortfolioAbout MeI started my career in machine learning and natural language processing (NLP) in 2015.From 2015 to 2019, I was a full-time machine learning engineer at the Chines">
<meta property="og:type" content="website">
<meta property="og:title" content="About Me">
<meta property="og:url" content="https://zihaowang.github.io/index.html">
<meta property="og:site_name" content="Zihao Wang&#39;s Portfolio">
<meta property="og:description" content="Zihao Wang’s Project PortfolioAbout MeI started my career in machine learning and natural language processing (NLP) in 2015.From 2015 to 2019, I was a full-time machine learning engineer at the Chines">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zihaowang.github.io/images/home1.jpg">
<meta property="article:published_time" content="2024-03-17T16:27:25.000Z">
<meta property="article:modified_time" content="2024-03-20T18:49:03.478Z">
<meta property="article:author" content="Zihao Wang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zihaowang.github.io/images/home1.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Zihao Wang's Portfolio" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.1.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Zihao Wang&#39;s Portfolio</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://zihaowang.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="page-" class="h-entry article article-type-page" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/index.html" class="article-date">
  <time class="dt-published" datetime="2024-03-17T16:27:25.000Z" itemprop="datePublished">2024-03-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      About Me
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="Zihao-Wang’s-Project-Portfolio"><a href="#Zihao-Wang’s-Project-Portfolio" class="headerlink" title="Zihao Wang’s Project Portfolio"></a>Zihao Wang’s Project Portfolio</h1><h2 id="About-Me"><a href="#About-Me" class="headerlink" title="About Me"></a>About Me</h2><p>I started my career in machine learning and natural language processing (NLP) in 2015.<br>From 2015 to 2019, I was a full-time machine learning engineer at the Chinese University of Hong Kong. During this period, I collaborated with several leading dot-com companies in different AI projects, which include:</p>
<ul>
<li>A project about <strong>E-commerce recommendation systems and text generation</strong>.</li>
<li>A project about <strong>text mining</strong> and <strong>automatic text summarization</strong>.</li>
</ul>
<p>From 2020, I am a Ph.D. student at the <a target="_blank" rel="noopener" href="https://www.ki.uni-stuttgart.de/departments/ac/">Analytic Computing group</a> of the University of Stuttgart, and I was also a full-time researcher working for the <a target="_blank" rel="noopener" href="https://www.servicemeister.org/en/">Service Meister</a> project funded by the Bundesministerium für Wirtschaft und Energie (BMWi). My research interests during this period include: </p>
<ul>
<li><strong>Knowledge graph (KG) embeddings</strong>.</li>
<li><strong>Vector Databases</strong>.</li>
<li><strong>Knowledge Graph Question answering systems</strong> on KGs and open-source texts using LLMs.</li>
<li><strong>Retrieval Augmented Generation</strong> on KGs and LLMs.</li>
</ul>
<p>You can also find me at <a target="_blank" rel="noopener" href="https://www.linkedin.com/in/zihaowang23/">LinkedIn</a> and <a target="_blank" rel="noopener" href="https://scholar.google.com/citations?user=4zcNt3IAAAAJ">Google Scholar</a>.</p>
<h2 id="My-Projects"><a href="#My-Projects" class="headerlink" title="My Projects"></a>My Projects</h2><h3 id="1-Knowledge-Graph-Question-Answering-Systems"><a href="#1-Knowledge-Graph-Question-Answering-Systems" class="headerlink" title="1. Knowledge Graph Question Answering Systems"></a>1. Knowledge Graph Question Answering Systems</h3><p><strong>Knowledge Graph Question Answering (KGQA)</strong> is an NLP task that focuses on developing systems capable of answering natural-language questions from humans using knowledge graphs. A <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> (KG) is a structured representation of information, typically entities, relations, and attributes. Below is an illustration of KGQA systems <a target="_blank" rel="noopener" href="https://medium.com/analytics-vidhya/open-domain-question-answering-series-part-3-introduction-to-knowledge-graphs-for-question-5d3f8d78812e">online</a>.”<br><img src="/images/home1.jpg" title="Fig. 1. A sketch diagram of KGQA systems."><br>Real-world KGs are highly incomplete, they may not contain all the information required to answer a given question. Texts, such as entity descriptions, documents, or other textual sources, provide additional context and details that might be missing in the structured KG.<br>Then, <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Language_model">Language models</a> play a crucial role in KGQA by providing natural language understanding, semantic representation, and adaptability to integrate texts with KGs.<br>In this project, we incorporate multiple language models for capturing word, sentence, and document levels of semantics from texts.<br>You may find more details at <a href="/2024/03/20/1_Knowledge_Graph_Question_Answering/" title="1_Knowledge_Graph_Question_Answering">this page</a>, or view our <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2208.02743">paper</a> and open-source code on <a target="_blank" rel="noopener" href="https://github.com/ZihaoWang/Hypercomplex-KG-Embedding">GitHub</a>.</p>
<h3 id="2-Knowledge-Graph-Embedding-with-LLMs"><a href="#2-Knowledge-Graph-Embedding-with-LLMs" class="headerlink" title="2. Knowledge Graph Embedding with LLMs"></a>2. Knowledge Graph Embedding with LLMs</h3><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Knowledge_graph_embedding">knowledge graph embedding</a> is a technique to represent entities and relations from a KG into continuous vector spaces, enabling effective reasoning and predictive tasks.<br>Below is an illustration of knowledge graph embeddings <a target="_blank" rel="noopener" href="https://towardsdatascience.com/knowledge-graph-embeddings-101-2cc1ca5db44f">online</a>, where connected entities are close to each other. For example, two entities “Liverpool” and “City” are close to each other in the 2D vector space. Below is an example of knowledge graph embeddings, where entities and relations are projected into a 2D vecor space.<br>![](&#x2F;image&#x2F;home2.jpg, Fig. 2. An example of knowledge graph embeddings.)<br>Embedding both knowledge graph entities and texts in a shared vector space enables their joint representations, which is beneficial for downstream NLP tasks, such as KGQA system with texts.\n\n<br>In this project, we jointly model the knowledge graph embeddings and text embeddings in the same space with recent LLMs such as GPT3.5 and OpenLLaMA.<br>Specifically, we have developed several methods of using LLMs:</p>
<ol>
<li>Directly process texts with LLMs, obtain text embeddings and design models to align text embeddings and knowledge graph embeddings in the same space.</li>
<li>Design prompt-based methods to obtain text and knowledge graph embeddings with LLMs.</li>
<li>Transform KGs into LLM-aware inputs and fine-tune LLMs to learn the knowledge graph embeddings, which are automatically aligned with the prior knowledge stored in LLMs.<br>You may find more details at <a href="/2024/03/20/2_Knowledge_Graph_Embedding_with_LLMs/" title="2_Knowledge_Graph_Embedding_with_LLMs">this page</a>.</li>
</ol>
<h3 id="3-Model-Uncommon-Concepts"><a href="#3-Model-Uncommon-Concepts" class="headerlink" title="3. Model Uncommon Concepts"></a>3. Model Uncommon Concepts</h3><p>Many concepts in vector databases and knowledge graphs, such as entities, nouns, and relations, are uncommon in daily life.<br>Modeling uncommon concepts is crucial for several reasons:</p>
<ol>
<li>Common concepts are often well-represented in vector databases or knowledge graphs. However, to achieve comprehensive coverage, it is essential to model and include information about uncommon ones.</li>
<li>Uncommon concepts often encapsulate specialized information, such as a specific medicine or tool.<br>In this project, we focus on modeling embeddings for uncommon concepts in KGs.<br>You may find more details at <a href="/2024/03/20/3_Modeling_Uncommon_Concepts/" title="3_Modeling_Uncommon_Concepts">this page</a>, or view our <a target="_blank" rel="noopener" href="https://aclanthology.org/D19-1024/">paper</a> and open-source code on <a target="_blank" rel="noopener" href="https://github.com/ZihaoWang/Few-shot-KGC">GitHub</a>.</li>
</ol>
<h3 id="4-Recommendation-Systems-with-Text-Generation"><a href="#4-Recommendation-Systems-with-Text-Generation" class="headerlink" title="4. Recommendation Systems with Text Generation"></a>4. Recommendation Systems with Text Generation</h3><p>A <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Recommender_system">recommendation system</a> is a software application that provides personalized suggestions or advice to users. It analyzes user preferences, behaviors, or past interactions to predict and offer items, services, or content that users might find interesting or relevant. Below is an illustration of a film recommendation system <a target="_blank" rel="noopener" href="https://www.nvidia.com/en-us/glossary/recommendation-system/">online</a>. If two users have similar tastes of films, the system will recommend the same film for them.<br>![](&#x2F;image&#x2F;home4.png, Fig. 4. An example of recommendation systems.)<br>In this project, we designed two recommendation systems.</p>
<ol>
<li>In the first recommendation system, we aim to develop a model that conducts the rating prediction and <strong>generates tips based on the predicted ratings.</strong></li>
<li>In the second recommendation system, we also <strong>consider users’ personas such as wording and style of writing tips</strong>, and we find that the quality of tips generation can be improved if the model considers the persona.<br>You may find more details at <a href="/2024/03/20/4_Recommendation_Systems_with_Text_Generation/" title="4_Recommendation_Systems_with_Text_Generation">this page</a>, or view our papers on <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1708.00154">the first recommendation system</a> and <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1903.02156">the second recommendation system</a>.</li>
</ol>
<h3 id="5-Abstractive-Text-Summarization-n-n"><a href="#5-Abstractive-Text-Summarization-n-n" class="headerlink" title="5. Abstractive Text Summarization\n\n"></a>5. Abstractive Text Summarization\n\n</h3><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Automatic_summarization">Automatic summarization</a> automatically generates a summary that retains the most important content of the original text document.<br>Among various methodologies, we explore <strong>abstractive summarization</strong> that reformulates the original text by generating new sentences capturing the text’s main ideas. This method is challenging as it requires understanding the context and generating content that may not exist verbatim in the original text. Below is an illustration of abstractive text summarization <a target="_blank" rel="noopener" href="https://turbolab.in/types-of-text-summarization-extractive-and-abstractive-summarization-basics/">online</a>, where new texts different than origin texts are generated in the summarization.<br>![](&#x2F;image&#x2F;home5.jpg, A illustration of abstractive text summarization.)<br>In this project, we propose an abstractive summarization method that incorporates the textual structure of summaries.<br>You may find more details at <a href="/2024/03/20/5_Abstractive_Text_Summarization/" title="5_Abstractive_Text_Summarization">this page</a>, or view our <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1708.00625">paper</a>.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://zihaowang.github.io/index.html" data-id="clu07rsqk0000ejf7crzuhcvk" data-title="About Me" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/03/20/knowledge-graph-embedding-with-LLMs/">(no title)</a>
          </li>
        
          <li>
            <a href="/2024/03/20/knowledge-graph-question-answering/">(no title)</a>
          </li>
        
          <li>
            <a href="/2024/03/20/abstractive-text-summarization/">(no title)</a>
          </li>
        
          <li>
            <a href="/2024/03/20/modeling-uncommon-knowledge/">(no title)</a>
          </li>
        
          <li>
            <a href="/2024/03/20/recommendation-systems/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 Zihao Wang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>